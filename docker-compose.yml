services:
  db:
    image: pgvector/pgvector:pg17
    ports:
      - 5433:5432
    networks:
      - trident
    restart: always
    environment:
      - POSTGRES_DB=verceldb
      - POSTGRES_USER=default
      - POSTGRES_PASSWORD=password
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "pg_isready -h localhost -U ${POSTGRES_USER:-default} -d ${POSTGRES_DB:-verceldb}",
        ]
      interval: 5s
      timeout: 5s
      retries: 10
  ollama:
    image: ollama/ollama:latest
    volumes:
      - ollama:/root/.ollama
    ports:
      - 1143:11434
    networks:
      - trident
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: ["gpu"]
    healthcheck:
      test: ["CMD", "bash", "-c", "ollama list | grep gpt-oss:20b"]
      interval: 10s
      timeout: 10s
      retries: 1000
  x-ollama-pull:
    image: ollama/ollama:latest
    container_name: ollama-pull
    volumes:
      - ollama:/root/.ollama
    entrypoint: /bin/sh
    command:
      - "-c"
      - "sleep 5; OLLAMA_HOST=ollama:11434 ollama pull snowflake-arctic-embed:22m; OLLAMA_HOST=ollama:11434 ollama pull qwen3:8b; OLLAMA_HOST=ollama:11434 ollama pull gpt-oss:20b"
    networks:
      - trident
  nextjs:
    build:
      context: .
      dockerfile: Dockerfile
    command: npm run dev
    depends_on:
      db:
        condition: service_healthy
      ollama:
        condition: service_healthy
    env_file:
      - .env.development
    volumes:
      - type: bind
        source: ${LOCAL_WORKSPACE_FOLDER:-.}
        target: /app
    ports:
      - 3000:3000
    networks:
      - trident

networks:
  trident:
    name: trident

volumes:
  ollama:
  overpass-db:
